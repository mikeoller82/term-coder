{"role": "user", "content": "add secirty and privacy featres", "ts": "2025-08-12T21:53:08.930994"}
{"role": "assistant", "content": "[MOCK:mock-llm] # File: src/term_coder/llm.py (score=0.063)\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom typing import Dict, Iterable, Iterator, List, Optional, Protocol\nimport os\nimport contextlib\n\n\n@dataclass\nclass Tool:\n    name: str\n    description: str\n\n\n@dataclass\nclass Response:\n    text: str\n    model: str\n\n\nclass ResponseChunk(Protocol):\n    def __str__(self) -> str: ...\n\n\nclass BaseLLMAdapter(Protocol):\n    \"\"\"Adapter interface for different LLM providers.\"\"\"\n\n    model_name: str\n\n    def complete(self, prompt: str, tools: Optional[List[Tool]] = None) -> Response:\n     ", "ts": "2025-08-12T21:53:08.932787"}
{"role": "user", "content": "hello", "ts": "2025-08-12T22:21:03.329710"}
{"role": "assistant", "content": "[MOCK:mock-llm] <history>\n[USER]\nadd secirty and privacy featres\n\n[ASSISTANT]\n[MOCK:mock-llm] # File: src/term_coder/llm.py (score=0.063)\nfrom __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom typing import Dict, Iterable, Iterator, List, Optional, Protocol\nimport os\nimport contextlib\n\n\n@dataclass\nclass Tool:\n    name: str\n    description: str\n\n\n@dataclass\nclass Response:\n    text: str\n    model: str\n\n\nclass ResponseChunk(Protocol):\n    def __str__(self) -> str: ...\n\n\nclass BaseLLMAdapter(Protocol):\n    \"\"\"Adapter interface for different LLM providers.\"\"\"\n\n    model_name: str\n\n    def comp", "ts": "2025-08-12T22:21:03.341912"}
